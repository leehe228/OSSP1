{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from my_models import ResNet101, xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import easydict\n",
    "from PIL import Image as im\n",
    "from PIL import ImageOps\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import sys\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "op = os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'COCO' from 'pycocotools' (/home/dmsai2/.conda/envs/openmmlab/lib/python3.8/site-packages/pycocotools/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptim\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lr_scheduler\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpycocotools\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m COCO\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'COCO' from 'pycocotools' (/home/dmsai2/.conda/envs/openmmlab/lib/python3.8/site-packages/pycocotools/__init__.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler\n",
    "import torchvision.models as models\n",
    "\n",
    "# from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-19_06_42\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/home/dmsai2/mmdetection/data/\"\n",
    "\n",
    "TRAIN_DATASET_DIR = op(DATA_DIR, \"classification\")\n",
    "TRAIN_IMAGE_DIR = op(TRAIN_DATASET_DIR, \"train\")\n",
    "TRAIN_JSON_DIR = op(TRAIN_DATASET_DIR, \"annotations\")\n",
    "\n",
    "TEST_DATASET_DIR = op(DATA_DIR, \"classification\")\n",
    "TEST_IMAGE_DIR = op(TEST_DATASET_DIR, \"test\")\n",
    "TEST_JSON_DIR = op(TEST_DATASET_DIR, \"annotations\")\n",
    "\n",
    "current_datetime = datetime.now()\n",
    "formatted_datetime = current_datetime.strftime('%Y-%m-%d_%H_%M')\n",
    "print(formatted_datetime)\n",
    "\n",
    "os.makedirs(op(\"/home/dmsai2/mmdetection/work_dir/classification/logs\", formatted_datetime), exist_ok=True)\n",
    "os.makedirs(op(\"/home/dmsai2/mmdetection/work_dir/classification/weights\", formatted_datetime), exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train file: 1991\n",
      "number of train file: 250\n"
     ]
    }
   ],
   "source": [
    "train_file_list = list(map(lambda x : x.split(\".\")[0], os.listdir(TRAIN_IMAGE_DIR)))\n",
    "train_image_list = os.listdir(TRAIN_IMAGE_DIR)\n",
    "train_json_list = os.listdir(TRAIN_JSON_DIR)\n",
    "print(\"number of train file:\", len(train_file_list))\n",
    "\n",
    "test_file_list = list(map(lambda x : x.split(\".\")[0], os.listdir(TEST_IMAGE_DIR)))\n",
    "test_image_list = os.listdir(TEST_IMAGE_DIR)\n",
    "test_json_list = os.listdir(TEST_JSON_DIR)\n",
    "print(\"number of train file:\", len(test_file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = pd.read_csv(\"/hoeunlee228/Dataset/train_df.csv\")\n",
    "# # print(train_df.head())\n",
    "# train_df['is_decayed'].value_counts()\n",
    "\n",
    "# not_decayed_rows = train_df[train_df['is_decayed'] == False]\n",
    "# decayed_rows = train_df[train_df['is_decayed'] == True]\n",
    "# print(\"total not decayed rows:\", len(not_decayed_rows), \"total decayed rows\", len(decayed_rows))\n",
    "\n",
    "# num_samples_not_decayed = 28136 * 3\n",
    "# num_samples_decayed = 28136\n",
    "\n",
    "# print(\"args num sampled not decayed:\", num_samples_not_decayed, \"args num sampled decayed:\", num_samples_decayed)\n",
    "\n",
    "# random_samples_not_decayed = random.sample(range(len(not_decayed_rows)), num_samples_not_decayed)\n",
    "# not_decayed_sampled_df = not_decayed_rows.iloc[random_samples_not_decayed]\n",
    "# print(\"num of not decayed sampled list\", len(not_decayed_sampled_df))\n",
    "\n",
    "# random_samples_decayed = random.sample(range(len(decayed_rows)), num_samples_decayed)\n",
    "# decayed_sampled_df = decayed_rows.iloc[random_samples_decayed]\n",
    "# print(\"num of decayed sampled list\", len(decayed_sampled_df))\n",
    "\n",
    "# train_file_list_not_decayed_sampled = list(map(lambda x : f\"{x[0]}_{x[1]}\", not_decayed_sampled_df[['file', 'teeth_idx']].values.tolist()))\n",
    "# train_file_list_decayed_sampled = list(map(lambda x : f\"{x[0]}_{x[1]}\", decayed_sampled_df[['file', 'teeth_idx']].values.tolist()))\n",
    "# print(\"num of sampled file list (not decayed, decayed):\", len(train_file_list_not_decayed_sampled), len(train_file_list_decayed_sampled))\n",
    "\n",
    "# sampled_train_list = train_file_list_not_decayed_sampled + train_file_list_decayed_sampled\n",
    "# print(\"total num of sampled train list:\", len(sampled_train_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class ToothDataset(Dataset):\n",
    "#     def __init__(self, data_dir, file_list, transform=None, aug_transform=None):\n",
    "#         self.data_dir = data_dir\n",
    "#         self.file_list = file_list\n",
    "#         self.transform = transform\n",
    "#         self.aug_transform = aug_transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.file_list)\n",
    "    \n",
    "#     def _load_image(self, image_path):\n",
    "#         assert os.path.exists(op(self.data_dir, \"image\", image_path))\n",
    "#         # return cv2.cvtColor(cv2.imread(op(self.data_dir, \"image\", image_path)), cv2.COLOR_BGR2RGB)\n",
    "#         return im.open(op(self.data_dir, \"image\", image_path)).convert(\"RGB\")\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "#         image_path = self.file_list[index] + \".png\"\n",
    "#         json_path = self.file_list[index] + \".json\"\n",
    "\n",
    "#         image = self._load_image(image_path)\n",
    "\n",
    "#         with open(op(self.data_dir, \"json\", json_path), 'r') as json_file:\n",
    "#             data = json.load(json_file)\n",
    "\n",
    "#         decayed = data[\"tooth\"][0][\"decayed\"]\n",
    "#         target = 1 if decayed else 0\n",
    "\n",
    "#         if self.transform:\n",
    "#             image = self.transform(image)\n",
    "\n",
    "#         if self.aug_transform:\n",
    "#             image = self.aug_transform(image)\n",
    "\n",
    "#         return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToothCOCODataset(Dataset):\n",
    "    def __init__(self, data_dir, ann_file, transform=None, aug_transform=None, valid=False):\n",
    "        self.data_dir = data_dir\n",
    "        self.coco = COCO(ann_file)\n",
    "        self.image_ids = self.coco.getImgIds()\n",
    "        self.transform = transform\n",
    "        self.aug_transform = aug_transform\n",
    "        self.valid = valid\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_ids)\n",
    "    \n",
    "    def _load_image(self, image_id):\n",
    "        image_info = self.coco.loadImgs(image_id)[0]\n",
    "        image_path = op(self.data_dir, image_info['file_name'])\n",
    "        assert os.path.exists(image_path), f\"Image path {image_path} does not exist.\"\n",
    "        \n",
    "        if self.valid:\n",
    "            return (im.open(image_path).convert(\"RGB\"), image_info['file_name'])\n",
    "        else:\n",
    "            return im.open(image_path).convert(\"RGB\")\n",
    "    \n",
    "    def _load_target(self, image_id):\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=image_id)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "        # Assuming 'decayed' is the attribute that indicates decay\n",
    "        # decayed = any(ann.get('category_id', False) for ann in anns)\n",
    "        decayed = any(ann.get('category_id', False) for ann in anns)\n",
    "        target = 1 if decayed else 0\n",
    "        return target\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_id = self.image_ids[index]\n",
    "\n",
    "        if self.valid:\n",
    "            image, label = self._load_image(image_id)\n",
    "        else:\n",
    "            image = self._load_image(image_id)\n",
    "\n",
    "        target = self._load_target(image_id)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.aug_transform:\n",
    "            image = self.aug_transform(image)\n",
    "\n",
    "        if self.valid:\n",
    "            return (image, label), target\n",
    "        else:\n",
    "            return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Zero padding to make the image square\n",
    "def make_square(img):\n",
    "    width, height = img.size\n",
    "    max_side = max(width, height)\n",
    "    left = (max_side - width) // 2\n",
    "    top = (max_side - height) // 2\n",
    "    right = (max_side - width) - left\n",
    "    bottom = (max_side - height) - top\n",
    "    padding = (left, top, right, bottom)\n",
    "    return ImageOps.expand(img, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.57933619, 0.42688786, 0.33401168)\n",
    "std = (0.35580848, 0.27125023, 0.22251333)\n",
    "\n",
    "test_aug_transform = transforms.Compose([\n",
    "    # 1. 이미지를 정사각형으로 만들기\n",
    "    transforms.Lambda(lambda img: ImageOps.exif_transpose(img)),  # Exif 정보 처리\n",
    "    transforms.Lambda(make_square),\n",
    "\n",
    "    # 2. Resize\n",
    "    transforms.Resize(size=(300, 300)),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "valid_aug_transform = transforms.Compose([\n",
    "    # 1. 이미지를 정사각형으로 만들기\n",
    "    transforms.Lambda(lambda img: ImageOps.exif_transpose(img)),  # Exif 정보 처리\n",
    "    transforms.Lambda(make_square),\n",
    "\n",
    "    # 2. Resize\n",
    "    transforms.Resize(size=(300, 300)),\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({    \n",
    "    \"gpu\": 0,\n",
    "    # 데이터 위치\n",
    "    \"root\": \"/home/dmsai2/mmdetection/data/classification/\",\n",
    "    # pth\n",
    "    \"save_fn\": \"/home/dmsai2/mmdetection/image-classification-fastapi/xception_epoch26.pth\"\n",
    "})\n",
    "\n",
    "assert os.path.isfile(args.save_fn), 'wrong path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'xception'\n"
     ]
    }
   ],
   "source": [
    "model = xception(num_out_classes=2, dropout=0.5)\n",
    "print(\"=> creating model '{}'\".format('xception'))\n",
    "model = model.cuda(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> model weight '/home/dmsai2/mmdetection/image-classification-fastapi/xception_epoch26.pth' is loaded\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(args.save_fn)['state_dict'])\n",
    "print(\"=> model weight '{}' is loaded\".format(args.save_fn))\n",
    "\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tooth: 0.8735164999961853, cavity: 0.12648352980613708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dmsai2/.conda/envs/openmmlab/lib/python3.8/site-packages/torch/nn/modules/module.py:1532: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  return self._call_impl(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# predict label\n",
    "m = nn.Softmax()\n",
    "\n",
    "with torch.no_grad():\n",
    "    image_path = \"/home/dmsai2/mmdetection/image-classification-fastapi/front_100_11.png\"\n",
    "    image = im.open(image_path).convert(\"RGB\")\n",
    "    image = valid_aug_transform(image)\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    image = image.cuda(args.gpu, non_blocking=True)\n",
    "    \n",
    "    output = model(image)\n",
    "    output = m(output)[0]\n",
    "    \n",
    "    print(f\"tooth: {output[0]}, cavity: {output[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect all images\n",
    "print(len(test_file_list))\n",
    "\n",
    "# prepare pred dict\n",
    "test_predict_dict = {}\n",
    "image_inf_list = []\n",
    "\n",
    "for f in os.listdir(\"/hoeunlee228/Dataset/test_data/image/\"):\n",
    "    test_predict_dict[f] = []\n",
    "\n",
    "# predict label\n",
    "m = nn.Softmax()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tf in tqdm(test_file_list):\n",
    "        image_path = op(TEST_DATASET_DIR, \"image\", tf + \".png\")\n",
    "        image = im.open(image_path).convert('RGB')\n",
    "        image = valid_aug_transform(image)\n",
    "        image = torch.unsqueeze(image, dim=0)\n",
    "        image = image.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        original_f = tf.split(\"_\")[0] + \"_\" + tf.split(\"_\")[1] + \".png\"\n",
    "        file_name = tf.split(\"_\")[0] + \"_\" + tf.split(\"_\")[1]\n",
    "        teeth_idx = int(tf.split(\"_\")[2])\n",
    "\n",
    "        output = model(image)\n",
    "        output = m(output)[0]  # apply softmax\n",
    "\n",
    "        # 0 = not decayed\n",
    "        # write to submission file\n",
    "        if output[0] > output[1]:\n",
    "            test_predict_dict[original_f].append(False)\n",
    "            image_inf_list.append([file_name, teeth_idx, False, (output[0].cpu().item(), output[1].cpu().item())])\n",
    "\n",
    "        # 1 = decayed\n",
    "        else:\n",
    "            test_predict_dict[original_f].append(True)\n",
    "            image_inf_list.append([file_name, teeth_idx, True, (output[0].cpu().item(), output[1].cpu().item())])\n",
    "\n",
    "print(\"predicted finished:\", len(test_predict_dict.keys()))\n",
    "print(\"len of preds:\", len(image_inf_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'efficientnet-b3'\n",
      "=> model weight '/hoeunlee228/weights/2023-12-16_02_49/efficientnetb3_epoch5.pth' is loaded\n"
     ]
    }
   ],
   "source": [
    "model = EfficientNet.from_name('efficientnet-b3')\n",
    "print(\"=> creating model '{}'\".format('efficientnet-b3'))\n",
    "model = model.cuda(args.gpu)\n",
    "\n",
    "# assert os.path.isfile(args.save_fn), 'wrong path'\n",
    "\n",
    "model.load_state_dict(torch.load(args.save_fn)['state_dict'])\n",
    "print(\"=> model weight '{}' is loaded\".format(args.save_fn))\n",
    "\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>teeth_idx</th>\n",
       "      <th>num_seg</th>\n",
       "      <th>is_decayed</th>\n",
       "      <th>bound_x</th>\n",
       "      <th>bound_size_x</th>\n",
       "      <th>bound_y</th>\n",
       "      <th>bound_size_y</th>\n",
       "      <th>data_type</th>\n",
       "      <th>image_type</th>\n",
       "      <th>is_side</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>front_100</td>\n",
       "      <td>11</td>\n",
       "      <td>974</td>\n",
       "      <td>False</td>\n",
       "      <td>(561, 925)</td>\n",
       "      <td>364</td>\n",
       "      <td>(0, 396)</td>\n",
       "      <td>396</td>\n",
       "      <td>test</td>\n",
       "      <td>front</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>front_100</td>\n",
       "      <td>12</td>\n",
       "      <td>790</td>\n",
       "      <td>False</td>\n",
       "      <td>(312, 573)</td>\n",
       "      <td>261</td>\n",
       "      <td>(35, 368)</td>\n",
       "      <td>333</td>\n",
       "      <td>test</td>\n",
       "      <td>front</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>front_100</td>\n",
       "      <td>13</td>\n",
       "      <td>713</td>\n",
       "      <td>False</td>\n",
       "      <td>(101, 329)</td>\n",
       "      <td>228</td>\n",
       "      <td>(69, 411)</td>\n",
       "      <td>342</td>\n",
       "      <td>test</td>\n",
       "      <td>front</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>front_100</td>\n",
       "      <td>14</td>\n",
       "      <td>459</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 167)</td>\n",
       "      <td>167</td>\n",
       "      <td>(183, 413)</td>\n",
       "      <td>230</td>\n",
       "      <td>test</td>\n",
       "      <td>front</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>front_100</td>\n",
       "      <td>21</td>\n",
       "      <td>929</td>\n",
       "      <td>False</td>\n",
       "      <td>(909, 1281)</td>\n",
       "      <td>372</td>\n",
       "      <td>(48, 408)</td>\n",
       "      <td>360</td>\n",
       "      <td>test</td>\n",
       "      <td>front</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file  teeth_idx  num_seg  is_decayed      bound_x  bound_size_x  \\\n",
       "0  front_100         11      974       False   (561, 925)           364   \n",
       "1  front_100         12      790       False   (312, 573)           261   \n",
       "2  front_100         13      713       False   (101, 329)           228   \n",
       "3  front_100         14      459       False     (0, 167)           167   \n",
       "4  front_100         21      929       False  (909, 1281)           372   \n",
       "\n",
       "      bound_y  bound_size_y data_type image_type  is_side  \n",
       "0    (0, 396)           396      test      front    False  \n",
       "1   (35, 368)           333      test      front     True  \n",
       "2   (69, 411)           342      test      front     True  \n",
       "3  (183, 413)           230      test      front     True  \n",
       "4   (48, 408)           360      test      front    False  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"/hoeunlee228/test_df.csv\", index_col=0)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/37489 [00:00<?, ?it/s]/tmp/ipykernel_55838/644755056.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = m(output)[0]  # apply softmax\n",
      "100%|██████████| 37489/37489 [16:01<00:00, 39.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted finished: 3000\n",
      "len of preds: 37489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# collect all images\n",
    "print(len(test_file_list))\n",
    "\n",
    "# prepare pred dict\n",
    "test_predict_dict = {}\n",
    "image_inf_list = []\n",
    "\n",
    "for f in os.listdir(\"/hoeunlee228/Dataset/test_data/image/\"):\n",
    "    test_predict_dict[f] = []\n",
    "\n",
    "# predict label\n",
    "m = nn.Softmax()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tf in tqdm(test_file_list):\n",
    "        image_path = op(TEST_DATASET_DIR, \"image\", tf + \".png\")\n",
    "        image = im.open(image_path).convert('RGB')\n",
    "        image = valid_aug_transform(image)\n",
    "        image = torch.unsqueeze(image, dim=0)\n",
    "        image = image.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        original_f = tf.split(\"_\")[0] + \"_\" + tf.split(\"_\")[1] + \".png\"\n",
    "        file_name = tf.split(\"_\")[0] + \"_\" + tf.split(\"_\")[1]\n",
    "        teeth_idx = int(tf.split(\"_\")[2])\n",
    "\n",
    "        output = model(image)\n",
    "        output = m(output)[0]  # apply softmax\n",
    "\n",
    "        # 0 = not decayed\n",
    "        # write to submission file\n",
    "        if output[0] > output[1]:\n",
    "            test_predict_dict[original_f].append(False)\n",
    "            image_inf_list.append([file_name, teeth_idx, False, (output[0].cpu().item(), output[1].cpu().item())])\n",
    "\n",
    "        # 1 = decayed\n",
    "        else:\n",
    "            test_predict_dict[original_f].append(True)\n",
    "            image_inf_list.append([file_name, teeth_idx, True, (output[0].cpu().item(), output[1].cpu().item())])\n",
    "\n",
    "print(\"predicted finished:\", len(test_predict_dict.keys()))\n",
    "print(\"len of preds:\", len(image_inf_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37489/37489 [01:49<00:00, 342.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35443/37489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct_count_image = 0\n",
    "inf_list_image = []\n",
    "\n",
    "for row in tqdm(image_inf_list):\n",
    "    # name, pred, answer, same\n",
    "    file_name = row[0]\n",
    "    teeth_idx = row[1]\n",
    "    f_pred = row[2]\n",
    "    # print(file_name, teeth_idx)\n",
    "    f_answer = test_df[(test_df['file'] == file_name) & (test_df['teeth_idx'] == teeth_idx)]['is_decayed'].values[0]\n",
    "    correct = (f_pred == f_answer)\n",
    "    # print(file_name, f_pred, f_answer, correct)\n",
    "    inf_list_image.append([file_name, f_pred, f_answer, correct])\n",
    "\n",
    "    if correct:\n",
    "        correct_count_image += 1\n",
    "\n",
    "print(f\"{correct_count_image}/{len(inf_list_image)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels and predictions\n",
    "labels_image = [item[2] for item in inf_list_image]\n",
    "predictions_image = [item[1] for item in inf_list_image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489\n",
      "36489 1000\n",
      "37489\n",
      "35073 2416\n"
     ]
    }
   ],
   "source": [
    "print(labels_image.count(0) + labels_image.count(1))\n",
    "print(labels_image.count(0), labels_image.count(1))\n",
    "\n",
    "print(predictions_image.count(0) + predictions_image.count(1))\n",
    "print(predictions_image.count(0), predictions_image.count(1))\n",
    "\n",
    "# Convert boolean values to integers (True -> 1, False -> 0)\n",
    "labels_image = [int(label) for label in labels_image]\n",
    "predictions_image = [int(prediction) for prediction in predictions_image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.945423991037371\n",
      "Precision: 0.28352649006622516\n",
      "Recall: 0.685\n",
      "AUC: 0.8187805228973115\n",
      "F1 Score: 0.4010538641686183\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy_image = accuracy_score(labels_image, predictions_image)\n",
    "precision_image = precision_score(labels_image, predictions_image)\n",
    "recall_image = recall_score(labels_image, predictions_image)\n",
    "auc_image = roc_auc_score(labels_image, predictions_image)\n",
    "f1_image = f1_score(labels_image, predictions_image)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_image)\n",
    "print(\"Precision:\", precision_image)\n",
    "print(\"Recall:\", recall_image)\n",
    "print(\"AUC:\", auc_image)\n",
    "print(\"F1 Score:\", f1_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34758  1731]\n",
      " [  315   685]]\n",
      "True Positive (TP): 685\n",
      "False Positive (FP): 1731\n",
      "True Negative (TN): 34758\n",
      "False Negative (FN): 315\n"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "conf_matrix_image = confusion_matrix(labels_image, predictions_image)\n",
    "print(conf_matrix_image)\n",
    "\n",
    "# Extract TP, FP, TN, FN\n",
    "tp = conf_matrix_image[1, 1]\n",
    "fp = conf_matrix_image[0, 1]\n",
    "tn = conf_matrix_image[0, 0]\n",
    "fn = conf_matrix_image[1, 0]\n",
    "\n",
    "print(\"True Positive (TP):\", tp)\n",
    "print(\"False Positive (FP):\", fp)\n",
    "print(\"True Negative (TN):\", tn)\n",
    "print(\"False Negative (FN):\", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total num of test data: 3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    2000\n",
       "True     1000\n",
       "Name: decayed, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_df = pd.read_csv(\"/hoeunlee228/test_image_df.csv\")\n",
    "print(\"total num of test data:\", len(test_image_df))\n",
    "test_image_df['decayed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [00:00, 22070.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2218/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "inf_list = []\n",
    "\n",
    "for index, row in tqdm(test_image_df.iterrows()):\n",
    "    # name, pred, answer, same\n",
    "    file_name = row['name']\n",
    "    f_answer = row['decayed']\n",
    "    f_pred = any(test_predict_dict[row['name'] + \".png\"])\n",
    "    correct = (f_pred == f_answer)\n",
    "    # print(file_name, f_pred, f_answer, correct)\n",
    "    inf_list.append([file_name, f_pred, f_answer, correct])\n",
    "\n",
    "    if correct:\n",
    "        correct_count += 1\n",
    "\n",
    "print(f\"{correct_count}/{len(test_image_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7393333333333333\n",
      "Precision: 0.5774147727272727\n",
      "Recall: 0.813\n",
      "AUC: 0.7577499999999999\n",
      "F1 Score: 0.6752491694352158\n"
     ]
    }
   ],
   "source": [
    "# Extract labels and predictions\n",
    "labels = [item[2] for item in inf_list]\n",
    "predictions = [item[1] for item in inf_list]\n",
    "\n",
    "# Convert boolean values to integers (True -> 1, False -> 0)\n",
    "labels = [int(label) for label in labels]\n",
    "predictions = [int(prediction) for prediction in predictions]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "precision = precision_score(labels, predictions)\n",
    "recall = recall_score(labels, predictions)\n",
    "auc = roc_auc_score(labels, predictions)\n",
    "f1 = f1_score(labels, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1405  595]\n",
      " [ 187  813]]\n",
      "True Positive (TP): 813\n",
      "False Positive (FP): 595\n",
      "True Negative (TN): 1405\n",
      "False Negative (FN): 187\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m현재 셀 또는 이전 셀에서 코드를 실행하는 동안 Kernel이 충돌했습니다. 셀의 코드를 검토하여 오류의 가능한 원인을 식별하세요. 자세한 내용을 보려면 <a href='https://aka.ms/vscodeJupyterKernelCrash'> 여기 </a> 를 클릭하세요. 자세한 내용은 Jupyter <a href='command:jupyter.viewOutput'>로그</a>를 참조하세요."
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Extract TP, FP, TN, FN\n",
    "tp = conf_matrix[1, 1]\n",
    "fp = conf_matrix[0, 1]\n",
    "tn = conf_matrix[0, 0]\n",
    "fn = conf_matrix[1, 0]\n",
    "\n",
    "print(\"True Positive (TP):\", tp)\n",
    "print(\"False Positive (FP):\", fp)\n",
    "print(\"True Negative (TN):\", tn)\n",
    "print(\"False Negative (FN):\", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
