{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import easydict\n",
    "from PIL import Image as im\n",
    "from PIL import ImageOps\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import sys\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "op = os.path.join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "from sklearn.metrics import precision_recall_fscore_support, roc_auc_score\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Directory Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-15_15_41\n"
     ]
    }
   ],
   "source": [
    "DATA_DIR = \"/hoeunlee228/Dataset/\"\n",
    "\n",
    "TRAIN_DATASET_DIR = op(DATA_DIR, \"train_odata\")\n",
    "TRAIN_IMAGE_DIR = op(TRAIN_DATASET_DIR, \"image\")\n",
    "TRAIN_JSON_DIR = op(TRAIN_DATASET_DIR, \"json\")\n",
    "\n",
    "TEST_DATASET_DIR = op(DATA_DIR, \"test_odata\")\n",
    "TEST_IMAGE_DIR = op(TEST_DATASET_DIR, \"image\")\n",
    "TEST_JSON_DIR = op(TEST_DATASET_DIR, \"json\")\n",
    "\n",
    "current_datetime = datetime.now()\n",
    "formatted_datetime = current_datetime.strftime('%Y-%m-%d_%H_%M')\n",
    "print(formatted_datetime)\n",
    "\n",
    "os.makedirs(op(\"/hoeunlee228/logs\", formatted_datetime), exist_ok=True)\n",
    "os.makedirs(op(\"/hoeunlee228/weights\", formatted_datetime), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read File List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of train file: 338719\n",
      "number of train file: 37489\n"
     ]
    }
   ],
   "source": [
    "train_file_list = list(map(lambda x : x.split(\".\")[0], os.listdir(TRAIN_IMAGE_DIR)))\n",
    "train_image_list = os.listdir(TRAIN_IMAGE_DIR)\n",
    "train_json_list = os.listdir(TRAIN_JSON_DIR)\n",
    "print(\"number of train file:\", len(train_file_list))\n",
    "\n",
    "test_file_list = list(map(lambda x : x.split(\".\")[0], os.listdir(TEST_IMAGE_DIR)))\n",
    "test_image_list = os.listdir(TEST_IMAGE_DIR)\n",
    "test_json_list = os.listdir(TEST_JSON_DIR)\n",
    "print(\"number of train file:\", len(test_file_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total not decayed rows: 310583 total decayed rows 28136\n",
      "args num sampled not decayed: 84408 args num sampled decayed: 28136\n",
      "num of not decayed sampled list 84408\n",
      "num of decayed sampled list 28136\n",
      "num of sampled file list (not decayed, decayed): 84408 28136\n",
      "total num of sampled train list: 112544\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"/hoeunlee228/Dataset/train_df.csv\")\n",
    "# print(train_df.head())\n",
    "train_df['is_decayed'].value_counts()\n",
    "\n",
    "not_decayed_rows = train_df[train_df['is_decayed'] == False]\n",
    "decayed_rows = train_df[train_df['is_decayed'] == True]\n",
    "print(\"total not decayed rows:\", len(not_decayed_rows), \"total decayed rows\", len(decayed_rows))\n",
    "\n",
    "num_samples_not_decayed = 28136 * 3\n",
    "num_samples_decayed = 28136\n",
    "\n",
    "print(\"args num sampled not decayed:\", num_samples_not_decayed, \"args num sampled decayed:\", num_samples_decayed)\n",
    "\n",
    "random_samples_not_decayed = random.sample(range(len(not_decayed_rows)), num_samples_not_decayed)\n",
    "not_decayed_sampled_df = not_decayed_rows.iloc[random_samples_not_decayed]\n",
    "print(\"num of not decayed sampled list\", len(not_decayed_sampled_df))\n",
    "\n",
    "random_samples_decayed = random.sample(range(len(decayed_rows)), num_samples_decayed)\n",
    "decayed_sampled_df = decayed_rows.iloc[random_samples_decayed]\n",
    "print(\"num of decayed sampled list\", len(decayed_sampled_df))\n",
    "\n",
    "train_file_list_not_decayed_sampled = list(map(lambda x : f\"{x[0]}_{x[1]}\", not_decayed_sampled_df[['file', 'teeth_idx']].values.tolist()))\n",
    "train_file_list_decayed_sampled = list(map(lambda x : f\"{x[0]}_{x[1]}\", decayed_sampled_df[['file', 'teeth_idx']].values.tolist()))\n",
    "print(\"num of sampled file list (not decayed, decayed):\", len(train_file_list_not_decayed_sampled), len(train_file_list_decayed_sampled))\n",
    "\n",
    "sampled_train_list = train_file_list_not_decayed_sampled + train_file_list_decayed_sampled\n",
    "print(\"total num of sampled train list:\", len(sampled_train_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToothDataset(Dataset):\n",
    "    def __init__(self, data_dir, file_list, transform=None, aug_transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.file_list = file_list\n",
    "        self.transform = transform\n",
    "        self.aug_transform = aug_transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "    \n",
    "    def _load_image(self, image_path):\n",
    "        assert os.path.exists(op(self.data_dir, \"image\", image_path))\n",
    "        # return cv2.cvtColor(cv2.imread(op(self.data_dir, \"image\", image_path)), cv2.COLOR_BGR2RGB)\n",
    "        return im.open(op(self.data_dir, \"image\", image_path)).convert(\"RGB\")\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = self.file_list[index] + \".png\"\n",
    "        json_path = self.file_list[index] + \".json\"\n",
    "\n",
    "        image = self._load_image(image_path)\n",
    "\n",
    "        with open(op(self.data_dir, \"json\", json_path), 'r') as json_file:\n",
    "            data = json.load(json_file)\n",
    "\n",
    "        decayed = data[\"tooth\"][0][\"decayed\"]\n",
    "        target = 1 if decayed else 0\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if self.aug_transform:\n",
    "            image = self.aug_transform(image)\n",
    "\n",
    "        return image, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeparableConv2d(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,kernel_size=1,stride=1,padding=0,dilation=1,bias=False):\n",
    "        super(SeparableConv2d,self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels,in_channels,kernel_size,stride,padding,dilation,groups=in_channels,bias=bias)\n",
    "        self.pointwise = nn.Conv2d(in_channels,out_channels,1,1,0,1,1,bias=bias)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "    def __init__(self,in_filters,out_filters,reps,strides=1,start_with_relu=True,grow_first=True):\n",
    "        super(Block, self).__init__()\n",
    "\n",
    "        if out_filters != in_filters or strides!=1:\n",
    "            self.skip = nn.Conv2d(in_filters,out_filters,1,stride=strides, bias=False)\n",
    "            self.skipbn = nn.BatchNorm2d(out_filters)\n",
    "        else:\n",
    "            self.skip=None\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        rep=[]\n",
    "\n",
    "        filters=in_filters\n",
    "        if grow_first:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
    "            rep.append(nn.BatchNorm2d(out_filters))\n",
    "            filters = out_filters\n",
    "\n",
    "        for i in range(reps-1):\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d(filters,filters,3,stride=1,padding=1,bias=False))\n",
    "            rep.append(nn.BatchNorm2d(filters))\n",
    "\n",
    "        if not grow_first:\n",
    "            rep.append(self.relu)\n",
    "            rep.append(SeparableConv2d(in_filters,out_filters,3,stride=1,padding=1,bias=False))\n",
    "            rep.append(nn.BatchNorm2d(out_filters))\n",
    "\n",
    "        if not start_with_relu:\n",
    "            rep = rep[1:]\n",
    "        else:\n",
    "            rep[0] = nn.ReLU(inplace=False)\n",
    "\n",
    "        if strides != 1:\n",
    "            rep.append(nn.MaxPool2d(3,strides,1))\n",
    "        self.rep = nn.Sequential(*rep)\n",
    "\n",
    "    def forward(self,inp):\n",
    "        x = self.rep(inp)\n",
    "\n",
    "        if self.skip is not None:\n",
    "            skip = self.skip(inp)\n",
    "            skip = self.skipbn(skip)\n",
    "        else:\n",
    "            skip = inp\n",
    "\n",
    "        x+=skip\n",
    "        return x\n",
    "\n",
    "\n",
    "class Xception(nn.Module):\n",
    "    def __init__(self, num_classes=1000):\n",
    "        super(Xception, self).__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3,32,3,2,0,bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(32,64,3,bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "\n",
    "        self.block1=Block(64,128,2,2,start_with_relu=False,grow_first=True)\n",
    "        self.block2=Block(128,256,2,2,start_with_relu=True,grow_first=True)\n",
    "        self.block3=Block(256,728,2,2,start_with_relu=True,grow_first=True)\n",
    "\n",
    "        self.block4=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block5=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block6=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block7=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "\n",
    "        self.block8=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block9=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block10=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "        self.block11=Block(728,728,3,1,start_with_relu=True,grow_first=True)\n",
    "\n",
    "        self.block12=Block(728,1024,2,2,start_with_relu=True,grow_first=False)\n",
    "\n",
    "        self.conv3 = SeparableConv2d(1024,1536,3,1,1)\n",
    "        self.bn3 = nn.BatchNorm2d(1536)\n",
    "\n",
    "        self.conv4 = SeparableConv2d(1536,2048,3,1,1)\n",
    "        self.bn4 = nn.BatchNorm2d(2048)\n",
    "\n",
    "        self.fc = nn.Linear(2048, num_classes)\n",
    "\n",
    "    def features(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "        x = self.block8(x)\n",
    "        x = self.block9(x)\n",
    "        x = self.block10(x)\n",
    "        x = self.block11(x)\n",
    "        x = self.block12(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        return x\n",
    "\n",
    "    def logits(self, features):\n",
    "        x = self.relu(features)\n",
    "\n",
    "        x = F.adaptive_avg_pool2d(x, (1, 1)) \n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.last_linear(x)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.features(input)\n",
    "        x = self.logits(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "## 기존 Xception에 Dropout만 추가\n",
    "class xception(nn.Module):\n",
    "    def __init__(self, num_out_classes=2, dropout=0.5):\n",
    "        super(xception, self).__init__()\n",
    "\n",
    "        self.model = Xception(num_classes=num_out_classes)\n",
    "        self.model.last_linear = self.model.fc\n",
    "        del self.model.fc\n",
    "\n",
    "        num_ftrs = self.model.last_linear.in_features\n",
    "        if not dropout:\n",
    "            self.model.last_linear = nn.Linear(num_ftrs, num_out_classes)\n",
    "        else:            \n",
    "            self.model.last_linear = nn.Sequential(\n",
    "                nn.Dropout(p=dropout),\n",
    "                nn.Linear(num_ftrs, num_out_classes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cudnn.benchmark = True\n",
    "\n",
    "args = easydict.EasyDict({\n",
    "    \"gpu\": 0,\n",
    "    \"num_workers\": 4,\n",
    "    \"root\": \"/hoeunlee228/Dataset/\",\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"num_epochs\": 50,\n",
    "    \"batch_size\": 32,\n",
    "\n",
    "    \"save_fn\": f\"/hoeunlee228/weights/{formatted_datetime}/xception\",\n",
    "    \"load_fn\": \"/hoeunlee228/weights/2023-12-15_00_43/xception_epoch0.pth\",\n",
    "    \"scheduler\": None,\n",
    "\n",
    "    \"scheduler_step\": 1,\n",
    "    \"scheduler_gamma\": 0.001\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Zero padding to make the image square\n",
    "def make_square(img):\n",
    "    width, height = img.size\n",
    "    max_side = max(width, height)\n",
    "    left = (max_side - width) // 2\n",
    "    top = (max_side - height) // 2\n",
    "    right = (max_side - width) - left\n",
    "    bottom = (max_side - height) - top\n",
    "    padding = (left, top, right, bottom)\n",
    "    return ImageOps.expand(img, padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.57933619, 0.42688786, 0.33401168)\n",
    "std = (0.35580848, 0.27125023, 0.22251333)\n",
    "\n",
    "\"\"\"train_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "valid_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(299, 299)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\"\"\"\n",
    "\n",
    "train_aug_transform = transforms.Compose([\n",
    "    # 1. 이미지를 정사각형으로 만들기\n",
    "    transforms.Lambda(lambda img: ImageOps.exif_transpose(img)),  # Exif 정보 처리\n",
    "    transforms.Lambda(make_square),\n",
    "\n",
    "    # 2. Resize\n",
    "    transforms.Resize(size=(299, 299)),\n",
    "\n",
    "    # 3. Augmentation\n",
    "    \n",
    "    transforms.RandomAffine(degrees=15, translate=(0.1, 0.1), scale=(0.9, 1.1), shear=10),\n",
    "    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1),\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "test_aug_transform = transforms.Compose([\n",
    "    # 1. 이미지를 정사각형으로 만들기\n",
    "    transforms.Lambda(lambda img: ImageOps.exif_transpose(img)),  # Exif 정보 처리\n",
    "    transforms.Lambda(make_square),\n",
    "\n",
    "    # 2. Resize\n",
    "    transforms.Resize(size=(299, 299)),\n",
    "    \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "valid_aug_transform = transforms.Compose([\n",
    "    # 1. 이미지를 정사각형으로 만들기\n",
    "    transforms.Lambda(lambda img: ImageOps.exif_transpose(img)),  # Exif 정보 처리\n",
    "    transforms.Lambda(make_square),\n",
    "\n",
    "    # 2. Resize\n",
    "    transforms.Resize(size=(299, 299)),\n",
    "\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean, std)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    torch.save(state, filename)\n",
    "    print(\"pth file saved at \" + filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, f\"/hoeunlee228/weights/{formatted_datetime}/model_best.pth.tar\")\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch, args):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train / validate\n",
    "def train(train_loader, model, criterion, optimizer, epoch, writer, step):   \n",
    "    n = 0\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "\n",
    "    error_count = {\n",
    "        \"precision\": 0,\n",
    "        \"recall\": 0,\n",
    "        \"auc\": 0\n",
    "    }\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    with tqdm(train_loader, total=len(train_loader), desc=\"Train\", file=sys.stdout) as iterator:\n",
    "        for images, target in iterator:\n",
    "            if args.gpu is not None:\n",
    "                images = images.cuda(args.gpu, non_blocking=True)\n",
    "                target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, pred = torch.max(outputs.data, 1)\n",
    "\n",
    "            loss = criterion(outputs, target)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            n += images.size(0)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_corrects += torch.sum(pred == target.data)\n",
    "\n",
    "            epoch_loss = running_loss / float(n)\n",
    "            epoch_acc = running_corrects / float(n)\n",
    "\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "\n",
    "            # Calculate F1-Score\n",
    "            f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "\n",
    "            # Calculate Precision and Recall\n",
    "            try:\n",
    "                precision = precision_score(all_targets, all_preds, average='weighted', zero_division=1)\n",
    "            except Exception as e:\n",
    "                precision = -1.0\n",
    "                error_count[\"precision\"] += 1\n",
    "\n",
    "            try:\n",
    "                recall = recall_score(all_targets, all_preds, average='weighted')\n",
    "            except Exception as e:\n",
    "                recall = -1.0\n",
    "                error_count[\"recall\"] += 1\n",
    "\n",
    "            # Calculate AUC\n",
    "            # fpr, tpr, _ = roc_curve(target.cpu(), outputs.data[:, 1].cpu())\n",
    "            # auc_value = roc_auc_score(target.cpu(), outputs.data[:, 1].cpu())\n",
    "            try:\n",
    "                # fpr, tpr, _ = roc_curve(all_targets, all_preds)\n",
    "                auc_value = roc_auc_score(all_targets, all_preds)\n",
    "            except Exception as e:\n",
    "                auc_value = -1.0\n",
    "                error_count[\"auc\"] += 1\n",
    "\n",
    "            log = 'loss - {:.4f}, acc - {:.4f}, F1 - {:.4f}, Precision - {:.4f}, Recall - {:.4f}, AUC - {:.4f}'.format(epoch_loss, epoch_acc, f1, precision, recall, auc_value)\n",
    "            iterator.set_postfix_str(log)\n",
    "\n",
    "            if step % 10 == 0:\n",
    "                writer.add_scalar(\"Train/Step/Loss\", epoch_loss, step)\n",
    "                writer.add_scalar(\"Train/Step/Accuracy\", epoch_acc, step)\n",
    "                writer.add_scalar(\"Train/Step/F1-Score\", f1, step)\n",
    "                writer.add_scalar(\"Train/Step/Precision\", precision, step)\n",
    "                writer.add_scalar(\"Train/Step/Recall\", recall, step)\n",
    "                writer.add_scalar(\"Train/Step/AUC\", auc_value, step)\n",
    "\n",
    "            step += 1\n",
    "\n",
    "    writer.add_scalar(\"Train/Epoch/Loss\", epoch_loss, epoch)\n",
    "    writer.add_scalar(\"Train/Epoch/Accuracy\", epoch_acc, epoch)\n",
    "    writer.add_scalar(\"Train/Epoch/F1-Score\", f1, epoch)\n",
    "    writer.add_scalar(\"Train/Epoch/Precision\", precision, epoch)\n",
    "    writer.add_scalar(\"Train/Epoch/Recall\", recall, epoch)\n",
    "    writer.add_scalar(\"Train/Epoch/AUC\", auc_value, epoch)\n",
    "\n",
    "    print(error_count)\n",
    "\n",
    "    # scheduler.step()\n",
    "\n",
    "    return step\n",
    "\n",
    "\n",
    "def validate(test_loader, model, criterion, epoch, writer):\n",
    "    n = 0\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "\n",
    "    all_targets = []\n",
    "    all_preds = []\n",
    "\n",
    "    error_count = {\n",
    "        \"precision\": 0,\n",
    "        \"recall\": 0,\n",
    "        \"auc\": 0\n",
    "    }\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with tqdm(test_loader, total=len(test_loader), desc=\"Valid\", file=sys.stdout) as iterator:\n",
    "        for images, target in iterator:\n",
    "            if args.gpu is not None:\n",
    "                images = images.cuda(args.gpu, non_blocking=True)\n",
    "                target = target.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                output = model(images)\n",
    "\n",
    "            loss = criterion(output, target)\n",
    "            _, pred = torch.max(output.data, 1)\n",
    "\n",
    "            n += images.size(0)\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            running_corrects += torch.sum(pred == target.data)\n",
    "\n",
    "            epoch_loss = running_loss / float(n)\n",
    "            epoch_acc = running_corrects / float(n)\n",
    "\n",
    "            all_targets.extend(target.cpu().numpy())\n",
    "            all_preds.extend(pred.cpu().numpy())\n",
    "\n",
    "            # Calculate F1-Score\n",
    "            f1 = f1_score(all_targets, all_preds, average='weighted')\n",
    "\n",
    "            try:\n",
    "                precision = precision_score(all_targets, all_preds, average='weighted', zero_division=1)\n",
    "            except Exception as e:\n",
    "                precision = -1.0\n",
    "                error_count[\"precision\"] += 1\n",
    "            \n",
    "            try:\n",
    "                recall = recall_score(all_targets, all_preds, average='weighted')\n",
    "            except Exception as e:\n",
    "                recall = -1.0\n",
    "                error_count[\"recall\"] += 1\n",
    "\n",
    "            # Calculate AUC\n",
    "            # fpr, tpr, _ = roc_curve(target.cpu(), output.data[:, 1].cpu())\n",
    "            # auc_value = roc_auc_score(target.cpu(), output.data[:, 1].cpu())\n",
    "            try:\n",
    "                # fpr, tpr, _ = roc_curve(all_targets, all_preds)\n",
    "                auc_value = roc_auc_score(all_targets, all_preds)\n",
    "            except Exception as e:\n",
    "                auc_value = -1.0\n",
    "                error_count[\"auc\"] += 1\n",
    "\n",
    "            log = 'loss - {:.4f}, acc - {:.4f}, F1 - {:.4f}, Precision - {:.4f}, Recall - {:.4f}, AUC - {:.4f}'.format(epoch_loss, epoch_acc, f1, precision, recall, auc_value)\n",
    "            iterator.set_postfix_str(log)\n",
    "\n",
    "    writer.add_scalar(\"Validation/Epoch/Loss\", epoch_loss, epoch)\n",
    "    writer.add_scalar(\"Validation/Epoch/Accuracy\", epoch_acc, epoch)\n",
    "    writer.add_scalar(\"Validation/Epoch/F1-Score\", f1, epoch)\n",
    "    writer.add_scalar(\"Validation/Epoch/Precision\", precision, epoch)\n",
    "    writer.add_scalar(\"Validation/Epoch/Recall\", recall, epoch)\n",
    "    writer.add_scalar(\"Validation/Epoch/AUC\", auc_value, epoch)\n",
    "\n",
    "    print(error_count)\n",
    "\n",
    "    return epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorboardX를 사용하여 summary writer 생성\n",
    "train_writer = SummaryWriter(f\"/hoeunlee228/logs/{formatted_datetime}/train\")  # 'logs/train'는 로그가 저장될 디렉토리입니다.\n",
    "test_writer = SummaryWriter(f\"/hoeunlee228/logs/{formatted_datetime}/validation\")  # 'logs/validation'은 로그가 저장될 디렉토리입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'xception'\n"
     ]
    }
   ],
   "source": [
    "model = xception(num_out_classes=2, dropout=0.5)\n",
    "print(\"=> creating model '{}'\".format('xception'))\n",
    "model = model.cuda(args.gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> model weight '/hoeunlee228/weights/2023-12-15_00_43/xception_epoch0.pth' is loaded\n"
     ]
    }
   ],
   "source": [
    "if args.load_fn is not None:\n",
    "    assert os.path.isfile(args.load_fn), 'wrong path'\n",
    "\n",
    "    model.load_state_dict(torch.load(args.load_fn)['state_dict'])\n",
    "    print(\"=> model weight '{}' is loaded\".format(args.load_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = optim.Adam(model.parameters(), lr=args.learning_rate, betas=(0.9, 0.999), eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.scheduler == \"steplr\":\n",
    "    print(\"StepLR selected to Scheduler\")\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, \n",
    "                                    step_size=args.scheduler_step,\n",
    "                                    gamma=args.scheduler_gamma)\n",
    "elif args.scheduler == 'exp':\n",
    "    print(\"ExponentialLR selected to Scheduler\")\n",
    "    scheduler = lr_scheduler.ExponentialLR(optimizer, \n",
    "                                    gamma=args.scheduler_gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "338719 37489\n"
     ]
    }
   ],
   "source": [
    "train_file_list = list(map(lambda x : x.split(\".\")[0], os.listdir(\"/hoeunlee228/Dataset/train_odata/image\")))\n",
    "test_file_list = list(map(lambda x : x.split(\".\")[0], os.listdir(\"/hoeunlee228/Dataset/test_odata/image\")))\n",
    "print(len(train_file_list), len(test_file_list))\n",
    "\n",
    "train_dataset = ToothDataset(data_dir=\"/hoeunlee228/Dataset/train_odata\",\n",
    "                             file_list=sampled_train_list,\n",
    "                             transform=train_aug_transform)\n",
    "\n",
    "valid_dataset = ToothDataset(data_dir=\"/hoeunlee228/Dataset/test_odata\",\n",
    "                             file_list=test_file_list,\n",
    "                             transform=test_aug_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset,\n",
    "                                           batch_size=args.batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=args.num_workers,\n",
    "                                           pin_memory=True,\n",
    "                                           )\n",
    "\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset,\n",
    "                                           batch_size=args.batch_size,\n",
    "                                           shuffle=False,\n",
    "                                           num_workers=args.num_workers,\n",
    "                                           pin_memory=False,\n",
    "                                           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "checking dataset and dataloader is okay...\n",
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"checking dataset and dataloader is okay...\")\n",
    "\n",
    "try:\n",
    "    _ = next(iter(train_loader))\n",
    "    print(\"ok\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    print(\"dataset or dataloader is not ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start training...\n",
      "--------------------------------------------------\n",
      "Epoch 1/50\n",
      "Train:   4%|▎         | 125/3517 [01:50<49:53,  1.13it/s, loss - 0.1950, acc - 0.916, F1 - 0.915, Precision - 0.915, Recall - 0.916, AUC - 0.877]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, args\u001b[38;5;241m.\u001b[39mnum_epochs))\n\u001b[0;32m----> 7\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_writer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m acc \u001b[38;5;241m=\u001b[39m validate(valid_loader, model, criterion, epoch, test_writer)\n\u001b[1;32m     10\u001b[0m save_checkpoint(state\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m: epoch,\n\u001b[1;32m     11\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m'\u001b[39m: model\u001b[38;5;241m.\u001b[39mstate_dict(),\n\u001b[1;32m     12\u001b[0m                        \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_acc1\u001b[39m\u001b[38;5;124m'\u001b[39m: acc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m                     filename\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39msave_fn \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m                 )\n",
      "Cell \u001b[0;32mIn[13], line 31\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch, writer, step)\u001b[0m\n\u001b[1;32m     29\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     30\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 31\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m n \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     34\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m images\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/hoeunlee228/anaconda3/envs/venv1/lib/python3.8/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.step\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hoeunlee228/anaconda3/envs/venv1/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hoeunlee228/anaconda3/envs/venv1/lib/python3.8/site-packages/torch/optim/adam.py:157\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    153\u001b[0m                 max_exp_avg_sqs\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_exp_avg_sq\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    155\u001b[0m             state_steps\u001b[38;5;241m.\u001b[39mappend(state[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m--> 157\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    158\u001b[0m \u001b[43m         \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m         \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m         \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m         \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m         \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m         \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m         \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m         \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[43m         \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    170\u001b[0m \u001b[43m         \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    171\u001b[0m \u001b[43m         \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m/hoeunlee228/anaconda3/envs/venv1/lib/python3.8/site-packages/torch/optim/adam.py:213\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 213\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    214\u001b[0m \u001b[43m     \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    215\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[43m     \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    218\u001b[0m \u001b[43m     \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    219\u001b[0m \u001b[43m     \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    220\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    221\u001b[0m \u001b[43m     \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[43m     \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    223\u001b[0m \u001b[43m     \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    224\u001b[0m \u001b[43m     \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    225\u001b[0m \u001b[43m     \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/hoeunlee228/anaconda3/envs/venv1/lib/python3.8/site-packages/torch/optim/adam.py:263\u001b[0m, in \u001b[0;36m_single_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;66;03m# Decay the first and second moment running average coefficient\u001b[39;00m\n\u001b[1;32m    262\u001b[0m exp_avg\u001b[38;5;241m.\u001b[39mmul_(beta1)\u001b[38;5;241m.\u001b[39madd_(grad, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta1)\n\u001b[0;32m--> 263\u001b[0m \u001b[43mexp_avg_sq\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39maddcmul_(grad, grad\u001b[38;5;241m.\u001b[39mconj(), value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m beta2)\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m capturable:\n\u001b[1;32m    266\u001b[0m     step \u001b[38;5;241m=\u001b[39m step_t\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"start training...\")\n",
    "step = 0\n",
    "\n",
    "for epoch in range(args.num_epochs):\n",
    "    print('-' * 50)\n",
    "    print('Epoch {}/{}'.format(epoch, args.num_epochs))\n",
    "    step = train(train_loader, model, criterion, optimizer, epoch, train_writer, step)\n",
    "    acc = validate(valid_loader, model, criterion, epoch, test_writer)\n",
    "\n",
    "    save_checkpoint(state={'epoch': epoch,\n",
    "                           'state_dict': model.state_dict(),\n",
    "                           'best_acc1': acc,\n",
    "                           'optimizer': optimizer.state_dict(),},\n",
    "                        is_best=False,\n",
    "                        filename=args.save_fn + f\"_epoch{epoch}.pth\",\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_writer.close()\n",
    "test_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({    \n",
    "    \"gpu\": 0,\n",
    "    # 데이터 위치\n",
    "    \"root\": \"/hoeunlee228/Dataset/test_odata/\",\n",
    "    # pth\n",
    "    \"save_fn\": \"/hoeunlee228/weights/2023-12-15_01_57/xception_epoch5.pth\"\n",
    "})\n",
    "\n",
    "assert os.path.isfile(args.save_fn), 'wrong path'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> creating model 'xception'\n",
      "=> model weight '/hoeunlee228/weights/2023-12-15_01_57/xception_epoch5.pth' is loaded\n"
     ]
    }
   ],
   "source": [
    "model = xception(num_out_classes=2, dropout=0.5)\n",
    "print(\"=> creating model '{}'\".format('xception'))\n",
    "model = model.cuda(args.gpu)\n",
    "\n",
    "assert os.path.isfile(args.save_fn), 'wrong path'\n",
    "\n",
    "model.load_state_dict(torch.load(args.save_fn)['state_dict'])\n",
    "print(\"=> model weight '{}' is loaded\".format(args.save_fn))\n",
    "\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>teeth_idx</th>\n",
       "      <th>num_seg</th>\n",
       "      <th>is_decayed</th>\n",
       "      <th>bound_x</th>\n",
       "      <th>bound_size_x</th>\n",
       "      <th>bound_y</th>\n",
       "      <th>bound_size_y</th>\n",
       "      <th>data_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>front_100</td>\n",
       "      <td>11</td>\n",
       "      <td>974</td>\n",
       "      <td>False</td>\n",
       "      <td>(561, 925)</td>\n",
       "      <td>364</td>\n",
       "      <td>(0, 396)</td>\n",
       "      <td>396</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>front_100</td>\n",
       "      <td>12</td>\n",
       "      <td>790</td>\n",
       "      <td>False</td>\n",
       "      <td>(312, 573)</td>\n",
       "      <td>261</td>\n",
       "      <td>(35, 368)</td>\n",
       "      <td>333</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>front_100</td>\n",
       "      <td>13</td>\n",
       "      <td>713</td>\n",
       "      <td>False</td>\n",
       "      <td>(101, 329)</td>\n",
       "      <td>228</td>\n",
       "      <td>(69, 411)</td>\n",
       "      <td>342</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>front_100</td>\n",
       "      <td>14</td>\n",
       "      <td>459</td>\n",
       "      <td>False</td>\n",
       "      <td>(0, 167)</td>\n",
       "      <td>167</td>\n",
       "      <td>(183, 413)</td>\n",
       "      <td>230</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>front_100</td>\n",
       "      <td>21</td>\n",
       "      <td>929</td>\n",
       "      <td>False</td>\n",
       "      <td>(909, 1281)</td>\n",
       "      <td>372</td>\n",
       "      <td>(48, 408)</td>\n",
       "      <td>360</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        file  teeth_idx  num_seg  is_decayed      bound_x  bound_size_x  \\\n",
       "0  front_100         11      974       False   (561, 925)           364   \n",
       "1  front_100         12      790       False   (312, 573)           261   \n",
       "2  front_100         13      713       False   (101, 329)           228   \n",
       "3  front_100         14      459       False     (0, 167)           167   \n",
       "4  front_100         21      929       False  (909, 1281)           372   \n",
       "\n",
       "      bound_y  bound_size_y data_type  \n",
       "0    (0, 396)           396      test  \n",
       "1   (35, 368)           333      test  \n",
       "2   (69, 411)           342      test  \n",
       "3  (183, 413)           230      test  \n",
       "4   (48, 408)           360      test  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"/hoeunlee228/test_df.csv\", index_col=0)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/37489 [00:00<?, ?it/s]/tmp/ipykernel_3701/1924618966.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  output = m(output)[0]  # apply softmax\n",
      "100%|██████████| 37489/37489 [20:09<00:00, 31.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted finished: 3000\n",
      "len of preds: 37489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# collect all images\n",
    "print(len(test_file_list))\n",
    "\n",
    "# prepare pred dict\n",
    "test_predict_dict = {}\n",
    "image_inf_list = []\n",
    "\n",
    "for f in os.listdir(\"/hoeunlee228/Dataset/test_data/image/\"):\n",
    "    test_predict_dict[f] = []\n",
    "\n",
    "# predict label\n",
    "m = nn.Softmax()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for tf in tqdm(test_file_list):\n",
    "        image_path = op(TEST_DATASET_DIR, \"image\", tf + \".png\")\n",
    "        image = im.open(image_path)\n",
    "        image = valid_aug_transform(image)\n",
    "        image = torch.unsqueeze(image, dim=0)\n",
    "        image = image.cuda(args.gpu, non_blocking=True)\n",
    "\n",
    "        original_f = tf.split(\"_\")[0] + \"_\" + tf.split(\"_\")[1] + \".png\"\n",
    "        file_name = tf.split(\"_\")[0] + \"_\" + tf.split(\"_\")[1]\n",
    "        teeth_idx = int(tf.split(\"_\")[2])\n",
    "\n",
    "        output = model(image)\n",
    "        output = m(output)[0]  # apply softmax\n",
    "\n",
    "        # 0 = not decayed\n",
    "        # write to submission file\n",
    "        if output[0] > output[1]:\n",
    "            test_predict_dict[original_f].append(False)\n",
    "            image_inf_list.append([file_name, teeth_idx, False])\n",
    "\n",
    "        # 1 = decayed\n",
    "        else:\n",
    "            test_predict_dict[original_f].append(True)\n",
    "            image_inf_list.append([file_name, teeth_idx, True])\n",
    "\n",
    "print(\"predicted finished:\", len(test_predict_dict.keys()))\n",
    "print(\"len of preds:\", len(image_inf_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37489/37489 [02:21<00:00, 264.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37272/37489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct_count_image = 0\n",
    "inf_list_image = []\n",
    "\n",
    "for row in tqdm(image_inf_list):\n",
    "    # name, pred, answer, same\n",
    "    file_name = row[0]\n",
    "    teeth_idx = row[1]\n",
    "    f_pred = row[2]\n",
    "    # print(file_name, teeth_idx)\n",
    "    f_answer = test_df[(test_df['file'] == file_name) & (test_df['teeth_idx'] == teeth_idx)]['is_decayed'].values[0]\n",
    "    correct = (f_pred == f_answer)\n",
    "    # print(file_name, f_pred, f_answer, correct)\n",
    "    inf_list_image.append([file_name, f_pred, f_answer, correct])\n",
    "\n",
    "    if correct:\n",
    "        correct_count_image += 1\n",
    "\n",
    "print(f\"{correct_count_image}/{len(inf_list_image)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels and predictions\n",
    "labels_image = [item[2] for item in inf_list_image]\n",
    "predictions_image = [item[1] for item in inf_list_image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37489\n",
      "36489 1000\n",
      "37489\n",
      "36612 877\n"
     ]
    }
   ],
   "source": [
    "print(labels_image.count(0) + labels_image.count(1))\n",
    "print(labels_image.count(0), labels_image.count(1))\n",
    "\n",
    "print(predictions_image.count(0) + predictions_image.count(1))\n",
    "print(predictions_image.count(0), predictions_image.count(1))\n",
    "\n",
    "# Convert boolean values to integers (True -> 1, False -> 0)\n",
    "labels_image = [int(label) for label in labels_image]\n",
    "predictions_image = [int(prediction) for prediction in predictions_image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9942116354130545\n",
      "Precision: 0.9464082098061574\n",
      "Recall: 0.83\n",
      "AUC: 0.9143559702924169\n",
      "F1 Score: 0.8843899840170485\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy_image = accuracy_score(labels_image, predictions_image)\n",
    "precision_image = precision_score(labels_image, predictions_image)\n",
    "recall_image = recall_score(labels_image, predictions_image)\n",
    "auc_image = roc_auc_score(labels_image, predictions_image)\n",
    "f1_image = f1_score(labels_image, predictions_image)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_image)\n",
    "print(\"Precision:\", precision_image)\n",
    "print(\"Recall:\", recall_image)\n",
    "print(\"AUC:\", auc_image)\n",
    "print(\"F1 Score:\", f1_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[36442    47]\n",
      " [  170   830]]\n",
      "True Positive (TP): 830\n",
      "False Positive (FP): 47\n",
      "True Negative (TN): 36442\n",
      "False Negative (FN): 170\n"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "conf_matrix_image = confusion_matrix(labels_image, predictions_image)\n",
    "print(conf_matrix_image)\n",
    "\n",
    "# Extract TP, FP, TN, FN\n",
    "tp = conf_matrix_image[1, 1]\n",
    "fp = conf_matrix_image[0, 1]\n",
    "tn = conf_matrix_image[0, 0]\n",
    "fn = conf_matrix_image[1, 0]\n",
    "\n",
    "print(\"True Positive (TP):\", tp)\n",
    "print(\"False Positive (FP):\", fp)\n",
    "print(\"True Negative (TN):\", tn)\n",
    "print(\"False Negative (FN):\", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total num of test data: 3000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False    2000\n",
       "True     1000\n",
       "Name: decayed, dtype: int64"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_image_df = pd.read_csv(\"/hoeunlee228/test_image_df.csv\")\n",
    "print(\"total num of test data:\", len(test_image_df))\n",
    "test_image_df['decayed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3000it [00:00, 18590.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2833/3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "correct_count = 0\n",
    "inf_list = []\n",
    "\n",
    "for index, row in tqdm(test_image_df.iterrows()):\n",
    "    # name, pred, answer, same\n",
    "    file_name = row['name']\n",
    "    f_answer = row['decayed']\n",
    "    f_pred = any(test_predict_dict[row['name'] + \".png\"])\n",
    "    correct = (f_pred == f_answer)\n",
    "    # print(file_name, f_pred, f_answer, correct)\n",
    "    inf_list.append([file_name, f_pred, f_answer, correct])\n",
    "\n",
    "    if correct:\n",
    "        correct_count += 1\n",
    "\n",
    "print(f\"{correct_count}/{len(test_image_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9443333333333334\n",
      "Precision: 0.997610513739546\n",
      "Recall: 0.835\n",
      "AUC: 0.9169999999999999\n",
      "F1 Score: 0.9090909090909092\n"
     ]
    }
   ],
   "source": [
    "# Extract labels and predictions\n",
    "labels = [item[2] for item in inf_list]\n",
    "predictions = [item[1] for item in inf_list]\n",
    "\n",
    "# Convert boolean values to integers (True -> 1, False -> 0)\n",
    "labels = [int(label) for label in labels]\n",
    "predictions = [int(prediction) for prediction in predictions]\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(labels, predictions)\n",
    "precision = precision_score(labels, predictions)\n",
    "recall = recall_score(labels, predictions)\n",
    "auc = roc_auc_score(labels, predictions)\n",
    "f1 = f1_score(labels, predictions)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC:\", auc)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1998    2]\n",
      " [ 165  835]]\n",
      "True Positive (TP): 835\n",
      "False Positive (FP): 2\n",
      "True Negative (TN): 1998\n",
      "False Negative (FN): 165\n"
     ]
    }
   ],
   "source": [
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(labels, predictions)\n",
    "print(conf_matrix)\n",
    "\n",
    "# Extract TP, FP, TN, FN\n",
    "tp = conf_matrix[1, 1]\n",
    "fp = conf_matrix[0, 1]\n",
    "tn = conf_matrix[0, 0]\n",
    "fn = conf_matrix[1, 0]\n",
    "\n",
    "print(\"True Positive (TP):\", tp)\n",
    "print(\"False Positive (FP):\", fp)\n",
    "print(\"True Negative (TN):\", tn)\n",
    "print(\"False Negative (FN):\", fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
