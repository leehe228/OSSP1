{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import mmcv\n",
    "from mmengine.config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmdet.apis.inference import init_detector, inference_detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_image(\n",
    "    config_path: Union[str, Path],\n",
    "    checkpoint_path: [str],\n",
    "    image_path: Union[str, np.ndarray],\n",
    "    device: str = 'cuda:0',\n",
    "    cfg_options: [dict] = None\n",
    ") -> Union[dict, list]:\n",
    "    \"\"\"\n",
    "    Perform inference on an image using a detector from MMDetection.\n",
    "\n",
    "    Args:\n",
    "        config_path (str or Path): Path to the model config file.\n",
    "        checkpoint_path (str, optional): Path to the model checkpoint file.\n",
    "        image_path (str or np.ndarray): Path to the image file or the image as a numpy array.\n",
    "        device (str): Device to run inference on. Defaults to 'cuda:0'.\n",
    "        cfg_options (dict, optional): Options to override some settings in the config. Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "        dict or list: Inference results. If the input is a list of images, the output will be a list of results.\n",
    "    \"\"\"\n",
    "    # Initialize the detector\n",
    "    model = init_detector(\n",
    "        config=config_path,\n",
    "        checkpoint=checkpoint_path,\n",
    "        device=device,\n",
    "        cfg_options=cfg_options\n",
    "    )\n",
    "\n",
    "    # Perform inference\n",
    "    # result = inference_detector(model, image_path)\n",
    "    \n",
    "    try:\n",
    "        # Perform inference\n",
    "        result = inference_detector(model, image_path)\n",
    "    finally:\n",
    "        # Clean up the GPU memory\n",
    "        del model\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_file = \"/home/dmsai2/mmdetection/my_configs/faster-renn_r101_fpn_1x_coco.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_file = \"/home/dmsai2/mmdetection/work_dir/epoch_48.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"./front_100.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loads checkpoint by local backend from path: /home/dmsai2/mmdetection/work_dir/epoch_48.pth\n"
     ]
    }
   ],
   "source": [
    "result = infer_image(config_file, checkpoint_file, image_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<DetDataSample(\n",
       "\n",
       "    META INFORMATION\n",
       "    batch_input_shape: (96, 224)\n",
       "    img_path: './front_100.png'\n",
       "    scale_factor: (0.1167274622199062, 0.11690140845070422)\n",
       "    pad_shape: (96, 224)\n",
       "    img_shape: (83, 224)\n",
       "    ori_shape: (710, 1919)\n",
       "    img_id: 0\n",
       "\n",
       "    DATA FIELDS\n",
       "    pred_instances: <InstanceData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "            bboxes: tensor([[ 899.2087,  360.8566, 1179.9043,  708.6053],\n",
       "                        [1259.7441,   90.6891, 1556.4888,  434.9768],\n",
       "                        [1146.5424,  361.3486, 1415.7355,  702.3556],\n",
       "                        [ 896.8765,   22.9528, 1296.3186,  431.6518],\n",
       "                        [ 453.5948,  361.5567,  710.9429,  689.8738],\n",
       "                        [ 249.5105,  365.6594,  483.3314,  662.6277],\n",
       "                        [ 291.9146,   41.4429,  579.9786,  387.3828],\n",
       "                        [ 563.7245,   16.6294,  923.7280,  397.3040],\n",
       "                        [ 679.8377,  391.1128,  922.6257,  696.1257],\n",
       "                        [1383.5455,  394.2423, 1634.3943,  695.4482],\n",
       "                        [  91.3104,  375.9558,  313.3632,  626.8344],\n",
       "                        [1560.9734,  378.8215, 1807.0820,  654.7260],\n",
       "                        [1690.8090,  169.9543, 1919.0000,  450.4976],\n",
       "                        [1734.1671,  392.7265, 1919.0000,  631.6373],\n",
       "                        [  84.6833,   63.0015,  324.0130,  425.7688],\n",
       "                        [1530.7885,   87.2094, 1770.2437,  429.6992],\n",
       "                        [   0.0000,  140.5114,  174.5451,  413.7718],\n",
       "                        [   9.2774,  381.6116,  140.6068,  567.9541],\n",
       "                        [   0.0000,  125.7351,   57.7661,  406.2975],\n",
       "                        [ 518.8943,  362.4636, 1448.5657,  697.7165],\n",
       "                        [ 219.9061,  356.6129, 1136.9563,  698.6747],\n",
       "                        [1823.1885,  258.3291, 1919.0000,  520.7931],\n",
       "                        [ 934.2158,  377.8057, 1532.7153,  702.8250],\n",
       "                        [ 226.0052,   13.2366, 1677.2784,  404.7514],\n",
       "                        [1809.6581,  138.2114, 1912.8837,  422.8628],\n",
       "                        [   0.0000,  215.8833,   99.7360,  429.1298],\n",
       "                        [ 331.9663,   15.1623,  857.3932,  417.0445],\n",
       "                        [  44.4352,  379.3082,  229.1580,  591.0885],\n",
       "                        [ 683.5392,    4.6250, 1153.3400,  410.2061],\n",
       "                        [ 858.5441,  440.6873,  964.3475,  644.3640],\n",
       "                        [1205.3831,  354.4737, 1850.0400,  694.9038],\n",
       "                        [ 859.7556,  120.6195,  989.1157,  274.6899]], device='cuda:0')\n",
       "            scores: tensor([0.9991, 0.9981, 0.9976, 0.9973, 0.9966, 0.9956, 0.9955, 0.9943, 0.9942,\n",
       "                        0.9924, 0.9923, 0.9923, 0.9910, 0.9909, 0.9902, 0.9857, 0.9648, 0.9024,\n",
       "                        0.7278, 0.3425, 0.2949, 0.2946, 0.1951, 0.1774, 0.1708, 0.1342, 0.1244,\n",
       "                        0.1038, 0.1018, 0.0950, 0.0780, 0.0595], device='cuda:0')\n",
       "            labels: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "                        0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0')\n",
       "        ) at 0x7fb8358dd730>\n",
       "    gt_instances: <InstanceData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
       "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
       "        ) at 0x7fb8358dd820>\n",
       "    ignored_instances: <InstanceData(\n",
       "        \n",
       "            META INFORMATION\n",
       "        \n",
       "            DATA FIELDS\n",
       "            bboxes: tensor([], device='cuda:0', size=(0, 4))\n",
       "            labels: tensor([], device='cuda:0', dtype=torch.int64)\n",
       "        ) at 0x7fb8358dd790>\n",
       ") at 0x7fb8358dd880>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from mmdet.structures import DetDataSample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boxes_on_image(\n",
    "    image_path: str,\n",
    "    result: DetDataSample,\n",
    "    output_path: str = 'output.jpg',\n",
    "    score_threshold: float = 0.3,\n",
    "    box_color: tuple = (0, 255, 0),\n",
    "    text_color: tuple = (0, 255, 0),\n",
    "    font_scale: float = 0.5,\n",
    "    thickness: int = 2\n",
    "):\n",
    "    \"\"\"\n",
    "    Draw bounding boxes on an image based on inference results.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the input image.\n",
    "        result (DetDataSample): Inference result containing bounding boxes and scores.\n",
    "        output_path (str): Path to save the output image with drawn boxes. Defaults to 'output.jpg'.\n",
    "        score_threshold (float): Minimum score threshold to draw the boxes. Defaults to 0.3.\n",
    "        box_color (tuple): Color of the bounding boxes. Defaults to (0, 255, 0).\n",
    "        text_color (tuple): Color of the text. Defaults to (0, 255, 0).\n",
    "        font_scale (float): Scale of the text font. Defaults to 0.5.\n",
    "        thickness (int): Thickness of the bounding boxes and text. Defaults to 2.\n",
    "    \"\"\"\n",
    "    # Load the image\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Image not found at {image_path}\")\n",
    "\n",
    "    # Extract bounding boxes and scores from the result\n",
    "    bboxes = result.pred_instances.bboxes.cpu().numpy()\n",
    "    scores = result.pred_instances.scores.cpu().numpy()\n",
    "    labels = result.pred_instances.labels.cpu().numpy()\n",
    "\n",
    "    # Loop through each detection\n",
    "    for bbox, score, label in zip(bboxes, scores, labels):\n",
    "        if score >= score_threshold:\n",
    "            x1, y1, x2, y2 = bbox.astype(int)\n",
    "            # Draw the bounding box\n",
    "            cv2.rectangle(image, (x1, y1), (x2, y2), box_color, thickness)\n",
    "            # Put label and score text above the bounding box\n",
    "            text = f'{label}: {score:.2f}'\n",
    "            (text_width, text_height), baseline = cv2.getTextSize(text, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)\n",
    "            cv2.rectangle(\n",
    "                image,\n",
    "                (x1, y1 - text_height - baseline),\n",
    "                (x1 + text_width, y1),\n",
    "                box_color,\n",
    "                -1\n",
    "            )\n",
    "            cv2.putText(image, text, (x1, y1 - baseline), cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, thickness)\n",
    "\n",
    "    # Save the output image\n",
    "    cv2.imwrite(output_path, image)\n",
    "    print(f\"Output image saved at {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = \"./test_output.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output image saved at ./test_output.jpg\n"
     ]
    }
   ],
   "source": [
    "draw_boxes_on_image(image_file, result, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openmmlab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
